{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalable Test Data Generator for Potential Failures\n",
    "\n",
    "This notebook generates comprehensive test data for the `app_potential_failures` table with the following features:\n",
    "\n",
    "## Features\n",
    "- ✅ Configurable data volume (~15k records, adjustable)\n",
    "- ✅ All KPI codes from `bronze.fms_dimkpiclassification`\n",
    "- ✅ Selectable KPI codes (all or specific)\n",
    "- ✅ Various task durations (short, medium, long) per KPI group\n",
    "- ✅ Financial year spanning jobs (at least 1 per KPI code)\n",
    "- ✅ Edge cases for downtime thresholds (24, 48, 100 hours)\n",
    "- ✅ Random start/end times over 2-year period starting 25/05/25\n",
    "- ✅ All jobs with COMP status\n",
    "- ✅ Period boundary crossing tasks\n",
    "- ✅ Distribution across all stations (excluding NULL sections)\n",
    "- ✅ Join with core_dimdate for period/week\n",
    "- ✅ Overlapping dates for duplicate testing\n",
    "- ✅ Configurable frequency per KPI code\n",
    "- ✅ Optional: Status simulation (WAPPR → APPR → COMP)\n",
    "- ✅ Optional: Non-KPI code tasks\n",
    "\n",
    "## Configuration Options\n",
    "See the configuration section below to customize data generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import uuid\n",
    "from typing import List, Dict, Optional\n",
    "import pyodbc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility (comment out for true randomness)\n",
    "# random.seed(42)\n",
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  CONFIGURATION FLAGS\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "CONFIG = {\n",
    "    # ─── Data Volume ───\n",
    "    'TOTAL_RECORDS': 15000,  # Target number of records to generate\n",
    "    \n",
    "    # ─── Date Range ───\n",
    "    'START_DATE': '2025-05-25',  # GTS started EL\n",
    "    'PERIOD_YEARS': 2,  # Generate data over 2 years\n",
    "    \n",
    "    # ─── KPI Code Selection ───\n",
    "    'USE_ALL_KPI_CODES': True,  # If False, use KPI_CODES_FILTER\n",
    "    'KPI_CODES_FILTER': [],  # e.g., ['GRAFFITI', 'TRACKSIDE'] - only used if USE_ALL_KPI_CODES = False\n",
    "    \n",
    "    # ─── KPI Code Frequency ───\n",
    "    # Weight distribution for KPI codes (higher = more records)\n",
    "    'KPI_FREQUENCY_WEIGHTS': {},  # e.g., {'GRAFFITI': 2.0, 'TRACKSIDE': 1.5} - empty means equal distribution\n",
    "    \n",
    "    # ─── Task Durations ───\n",
    "    'DURATION_CATEGORIES': {\n",
    "        'short': {'min_hours': 1, 'max_hours': 24, 'weight': 0.4},\n",
    "        'medium': {'min_hours': 25, 'max_hours': 120, 'weight': 0.4},\n",
    "        'long': {'min_hours': 121, 'max_hours': 720, 'weight': 0.2},\n",
    "    },\n",
    "    \n",
    "    # ─── Edge Cases ───\n",
    "    'YEAR_SPANNING_PER_KPI': 1,  # At least 1 year-spanning job per KPI code\n",
    "    'DOWNTIME_THRESHOLD_TESTS': True,  # Create jobs with 24, 48, 100 hour thresholds\n",
    "    'PERIOD_BOUNDARY_CROSSING_RATIO': 0.3,  # 30% of jobs should cross period boundaries\n",
    "    \n",
    "    # ─── Duplicate Testing ───\n",
    "    'CREATE_OVERLAPPING_GROUPS': True,  # Create overlapping date groups\n",
    "    'OVERLAPPING_GROUPS_COUNT': 50,  # Number of overlap groups to create\n",
    "    'OVERLAP_WINDOW_HOURS': 6,  # Tasks within 6 hours are considered overlapping\n",
    "    \n",
    "    # ─── Status ───\n",
    "    'ALL_COMPLETED': True,  # All jobs COMP status\n",
    "    \n",
    "    # ─── Output ───\n",
    "    'OUTPUT_MODE': 'LAKEHOUSE',  # 'LAKEHOUSE' or 'SQL_SERVER'\n",
    "    'LAKEHOUSE_PATH': '/lakehouse/default/Tables/test_potential_failures',  # For validation\n",
    "    'SQL_TABLE_NAME': 'customer_success.app_potential_failures_test',  # Final table\n",
    "    \n",
    "    # ─── Optional Features ───\n",
    "    'GENERATE_STATUS_HISTORY': False,  # Generate WAPPR → APPR → COMP history files\n",
    "    'INCLUDE_NON_KPI_CODES': False,  # Include non-KPI tasks\n",
    "    'NON_KPI_RATIO': 0.1,  # 10% non-KPI tasks if enabled\n",
    "    \n",
    "    # ─── Database Connection ───\n",
    "    'SQL_CONNECTION_STRING': None,  # Set to None to use Fabric default\n",
    "}\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  Target Records: {CONFIG['TOTAL_RECORDS']:,}\")\n",
    "print(f\"  Date Range: {CONFIG['START_DATE']} + {CONFIG['PERIOD_YEARS']} years\")\n",
    "print(f\"  Output Mode: {CONFIG['OUTPUT_MODE']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Connection & Reference Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  DATABASE CONNECTION\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "def get_connection():\n",
    "    \"\"\"Get database connection (Fabric or custom)\"\"\"\n",
    "    if CONFIG['SQL_CONNECTION_STRING']:\n",
    "        return pyodbc.connect(CONFIG['SQL_CONNECTION_STRING'])\n",
    "    else:\n",
    "        # Use Fabric notebook connection\n",
    "        from notebookutils import mssparkutils\n",
    "        return mssparkutils.credentials.getConnectionString()\n",
    "\n",
    "def load_reference_data():\n",
    "    \"\"\"Load KPI codes, stations, and date dimensions\"\"\"\n",
    "    print(\"Loading reference data...\")\n",
    "    \n",
    "    # Load KPI Classification codes\n",
    "    kpi_query = \"\"\"\n",
    "    SELECT DISTINCT \n",
    "        KPICode,\n",
    "        KPIDescription,\n",
    "        KPICategory,\n",
    "        ThresholdHours\n",
    "    FROM bronze.fms_dimkpiclassification\n",
    "    WHERE IsKPI = 1\n",
    "    ORDER BY KPICode\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load Stations (excluding NULL sections/depots)\n",
    "    station_query = \"\"\"\n",
    "    SELECT DISTINCT\n",
    "        StationCode as Building,\n",
    "        StationName as BuildingName,\n",
    "        LocationName,\n",
    "        StationSection\n",
    "    FROM customer_success.dimStation\n",
    "    WHERE StationSection IS NOT NULL\n",
    "        AND StationCode IS NOT NULL\n",
    "    ORDER BY StationCode\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load Date Dimension with Period information\n",
    "    date_query = \"\"\"\n",
    "    SELECT \n",
    "        Date,\n",
    "        Period,\n",
    "        PeriodWeek,\n",
    "        PeriodYear,\n",
    "        FinancialYear\n",
    "    FROM core_dimdate\n",
    "    WHERE Date BETWEEN '2025-05-25' AND '2027-05-31'\n",
    "    ORDER BY Date\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use Spark SQL in Fabric\n",
    "        kpi_codes = spark.sql(kpi_query).toPandas()\n",
    "        stations = spark.sql(station_query).toPandas()\n",
    "        date_dim = spark.sql(date_query).toPandas()\n",
    "        \n",
    "        print(f\"  ✓ Loaded {len(kpi_codes)} KPI codes\")\n",
    "        print(f\"  ✓ Loaded {len(stations)} stations\")\n",
    "        print(f\"  ✓ Loaded {len(date_dim)} dates\")\n",
    "        \n",
    "        return kpi_codes, stations, date_dim\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠ Error loading reference data: {e}\")\n",
    "        print(\"  Using mock data for demonstration...\")\n",
    "        return create_mock_reference_data()\n",
    "\n",
    "def create_mock_reference_data():\n",
    "    \"\"\"Create mock data for testing without database access\"\"\"\n",
    "    \n",
    "    # Mock KPI codes\n",
    "    kpi_codes = pd.DataFrame({\n",
    "        'KPICode': ['GRAFFITI', 'TRACKSIDE', 'PLATFORM_CLEAN', 'LIFT_MAINT', 'ESCALATOR', \n",
    "                    'LIGHTING', 'SIGNAGE', 'DRAINAGE', 'FIRE_SAFETY', 'ACCESS_CONTROL'],\n",
    "        'KPIDescription': ['Graffiti Removal', 'Trackside Cleaning', 'Platform Cleaning', \n",
    "                          'Lift Maintenance', 'Escalator Maintenance', 'Lighting Repair',\n",
    "                          'Signage Updates', 'Drainage Maintenance', 'Fire Safety Checks',\n",
    "                          'Access Control Maintenance'],\n",
    "        'KPICategory': ['Cleaning', 'Cleaning', 'Cleaning', 'Mechanical', 'Mechanical',\n",
    "                       'Electrical', 'Infrastructure', 'Infrastructure', 'Safety', 'Security'],\n",
    "        'ThresholdHours': [24, 48, 24, 100, 100, 48, 24, 48, 24, 48]\n",
    "    })\n",
    "    \n",
    "    # Mock stations\n",
    "    stations = pd.DataFrame({\n",
    "        'Building': ['KGX', 'STN', 'LIV', 'MAN', 'BHM', 'EDI', 'GLA', 'LEE', 'BRI', 'CAR',\n",
    "                     'OXF', 'CAM', 'YRK', 'NEW', 'SHE', 'NOR', 'IPS', 'PET', 'MKC', 'WAT'],\n",
    "        'BuildingName': ['Kings Cross', 'Stratford', 'Liverpool Street', 'Manchester Piccadilly',\n",
    "                        'Birmingham New Street', 'Edinburgh Waverley', 'Glasgow Central',\n",
    "                        'Leeds Station', 'Bristol Temple Meads', 'Cardiff Central',\n",
    "                        'Oxford Station', 'Cambridge Station', 'York Station', 'Newcastle Central',\n",
    "                        'Sheffield Station', 'Norwich Station', 'Ipswich Station', 'Peterborough',\n",
    "                        'Milton Keynes Central', 'Waterloo'],\n",
    "        'LocationName': ['London', 'London', 'London', 'Manchester', 'Birmingham', 'Edinburgh',\n",
    "                        'Glasgow', 'Leeds', 'Bristol', 'Cardiff', 'Oxford', 'Cambridge', 'York',\n",
    "                        'Newcastle', 'Sheffield', 'Norwich', 'Ipswich', 'Peterborough',\n",
    "                        'Milton Keynes', 'London'],\n",
    "        'StationSection': ['Main', 'Main', 'Main', 'Main', 'Main', 'Main', 'Main', 'Main',\n",
    "                          'Main', 'Main', 'Main', 'Main', 'Main', 'Main', 'Main', 'Main',\n",
    "                          'Main', 'Main', 'Main', 'Main']\n",
    "    })\n",
    "    \n",
    "    # Mock date dimension\n",
    "    start = pd.to_datetime('2025-05-25')\n",
    "    dates = pd.date_range(start, periods=730, freq='D')\n",
    "    date_dim = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "    })\n",
    "    \n",
    "    # Calculate Period, PeriodWeek, PeriodYear, FinancialYear\n",
    "    def get_period_info(date):\n",
    "        # Simplified period logic (4-week periods)\n",
    "        year = date.year if date.month >= 4 else date.year - 1\n",
    "        fy_start = pd.to_datetime(f'{year}-04-01')\n",
    "        days_since = (date - fy_start).days\n",
    "        period = min((days_since // 28) + 1, 13)\n",
    "        week = min((days_since // 7) + 1, 52)\n",
    "        return period, week, year\n",
    "    \n",
    "    date_dim[['Period', 'PeriodWeek', 'PeriodYear']] = date_dim['Date'].apply(\n",
    "        lambda x: pd.Series(get_period_info(x))\n",
    "    )\n",
    "    date_dim['FinancialYear'] = date_dim['PeriodYear'].apply(lambda x: f'FY{x}/{str(x+1)[-2:]}')\n",
    "    date_dim['Period'] = date_dim['Period'].apply(lambda x: f'P{x:02d}')\n",
    "    \n",
    "    print(f\"  ✓ Created {len(kpi_codes)} mock KPI codes\")\n",
    "    print(f\"  ✓ Created {len(stations)} mock stations\")\n",
    "    print(f\"  ✓ Created {len(date_dim)} mock dates\")\n",
    "    \n",
    "    return kpi_codes, stations, date_dim\n",
    "\n",
    "# Load or create reference data\n",
    "kpi_codes_df, stations_df, date_dim_df = load_reference_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter KPI codes based on configuration\n",
    "if not CONFIG['USE_ALL_KPI_CODES'] and CONFIG['KPI_CODES_FILTER']:\n",
    "    kpi_codes_df = kpi_codes_df[kpi_codes_df['KPICode'].isin(CONFIG['KPI_CODES_FILTER'])]\n",
    "    print(f\"Filtered to {len(kpi_codes_df)} KPI codes: {CONFIG['KPI_CODES_FILTER']}\")\n",
    "\n",
    "# Display reference data summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REFERENCE DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nKPI Codes ({len(kpi_codes_df)}):\")\n",
    "print(kpi_codes_df.head(10))\n",
    "print(f\"\\nStations ({len(stations_df)}):\")\n",
    "print(stations_df.head(10))\n",
    "print(f\"\\nDate Range: {date_dim_df['Date'].min()} to {date_dim_df['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  HELPER FUNCTIONS\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "def random_datetime(start_date, end_date):\n",
    "    \"\"\"Generate random datetime between start and end\"\"\"\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    delta = (end - start).total_seconds()\n",
    "    random_seconds = random.uniform(0, delta)\n",
    "    return start + timedelta(seconds=random_seconds)\n",
    "\n",
    "def get_duration_category():\n",
    "    \"\"\"Select duration category based on weights\"\"\"\n",
    "    categories = list(CONFIG['DURATION_CATEGORIES'].keys())\n",
    "    weights = [CONFIG['DURATION_CATEGORIES'][cat]['weight'] for cat in categories]\n",
    "    return random.choices(categories, weights=weights)[0]\n",
    "\n",
    "def generate_duration_hours(category=None):\n",
    "    \"\"\"Generate task duration in hours\"\"\"\n",
    "    if category is None:\n",
    "        category = get_duration_category()\n",
    "    \n",
    "    min_h = CONFIG['DURATION_CATEGORIES'][category]['min_hours']\n",
    "    max_h = CONFIG['DURATION_CATEGORIES'][category]['max_hours']\n",
    "    return random.uniform(min_h, max_h)\n",
    "\n",
    "def get_period_info_for_date(date, date_dim_df):\n",
    "    \"\"\"Get period information for a given date\"\"\"\n",
    "    date = pd.to_datetime(date).normalize()\n",
    "    match = date_dim_df[date_dim_df['Date'] == date]\n",
    "    if len(match) > 0:\n",
    "        row = match.iloc[0]\n",
    "        return row['Period'], row['PeriodWeek'], row['PeriodYear']\n",
    "    return None, None, None\n",
    "\n",
    "def generate_task_id():\n",
    "    \"\"\"Generate unique task ID\"\"\"\n",
    "    return f\"TASK-{uuid.uuid4().hex[:8].upper()}\"\n",
    "\n",
    "def generate_record_id():\n",
    "    \"\"\"Generate unique record ID\"\"\"\n",
    "    return f\"REC-{uuid.uuid4().hex[:12].upper()}\"\n",
    "\n",
    "# Sample data pools\n",
    "REPORTERS = [\n",
    "    ('John Smith', 'john.smith@gts.com'),\n",
    "    ('Sarah Johnson', 'sarah.johnson@gts.com'),\n",
    "    ('Michael Brown', 'michael.brown@gts.com'),\n",
    "    ('Emma Wilson', 'emma.wilson@gts.com'),\n",
    "    ('David Lee', 'david.lee@gts.com'),\n",
    "    ('Lisa Anderson', 'lisa.anderson@gts.com'),\n",
    "    ('James Taylor', 'james.taylor@gts.com'),\n",
    "    ('Sophie Martin', 'sophie.martin@gts.com'),\n",
    "]\n",
    "\n",
    "LOGGED_BY = [\n",
    "    'System_Auto',\n",
    "    'Maintenance_Team',\n",
    "    'Operations_Manager',\n",
    "    'Station_Manager',\n",
    "    'Facilities_Team',\n",
    "]\n",
    "\n",
    "SHORT_DESCRIPTIONS = {\n",
    "    'GRAFFITI': ['Graffiti on platform wall', 'Graffiti on ticket machine', 'Graffiti in waiting area'],\n",
    "    'TRACKSIDE': ['Trackside debris removal', 'Trackside vegetation clearance', 'Trackside litter collection'],\n",
    "    'PLATFORM_CLEAN': ['Platform cleaning required', 'Spillage cleanup', 'General platform maintenance'],\n",
    "    'LIFT_MAINT': ['Lift routine maintenance', 'Lift repair required', 'Lift safety inspection'],\n",
    "    'ESCALATOR': ['Escalator maintenance', 'Escalator cleaning', 'Escalator safety check'],\n",
    "    'LIGHTING': ['Light bulb replacement', 'Lighting circuit repair', 'Emergency lighting check'],\n",
    "    'SIGNAGE': ['Sign replacement', 'Directional sign update', 'Digital display repair'],\n",
    "    'DRAINAGE': ['Drain clearance', 'Drainage system inspection', 'Gully cleaning'],\n",
    "    'FIRE_SAFETY': ['Fire alarm test', 'Fire extinguisher check', 'Emergency exit inspection'],\n",
    "    'ACCESS_CONTROL': ['Access barrier repair', 'Gate maintenance', 'Ticket barrier service'],\n",
    "}\n",
    "\n",
    "SLA_STATUS = ['Within SLA', 'Near SLA', 'SLA Breach']\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  CORE DATA GENERATION\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "def create_base_task(kpi_code, station, reported_date, duration_hours, \n",
    "                     duration_category='medium', is_year_spanning=False):\n",
    "    \"\"\"Create a single task record\"\"\"\n",
    "    \n",
    "    kpi_info = kpi_codes_df[kpi_codes_df['KPICode'] == kpi_code].iloc[0]\n",
    "    \n",
    "    # Generate times\n",
    "    reported_dt = pd.to_datetime(reported_date)\n",
    "    scheduled_dt = reported_dt + timedelta(hours=random.uniform(1, 24))\n",
    "    started_dt = scheduled_dt + timedelta(hours=random.uniform(0, 12))\n",
    "    finished_dt = started_dt + timedelta(hours=duration_hours)\n",
    "    \n",
    "    # Due date based on KPI threshold\n",
    "    due_dt = reported_dt + timedelta(hours=kpi_info['ThresholdHours'])\n",
    "    \n",
    "    # Logged and modified dates\n",
    "    logged_dt = reported_dt - timedelta(minutes=random.uniform(0, 30))\n",
    "    modified_dt = finished_dt + timedelta(minutes=random.uniform(0, 60))\n",
    "    \n",
    "    # SLA status\n",
    "    hours_to_complete = (finished_dt - reported_dt).total_seconds() / 3600\n",
    "    if hours_to_complete <= kpi_info['ThresholdHours'] * 0.8:\n",
    "        sla_status = 'Within SLA'\n",
    "    elif hours_to_complete <= kpi_info['ThresholdHours']:\n",
    "        sla_status = 'Near SLA'\n",
    "    else:\n",
    "        sla_status = 'SLA Breach'\n",
    "    \n",
    "    # Get reporter\n",
    "    reporter, email = random.choice(REPORTERS)\n",
    "    \n",
    "    # Get short description\n",
    "    short_desc = random.choice(SHORT_DESCRIPTIONS.get(kpi_code, ['Maintenance task required']))\n",
    "    long_desc = f\"{short_desc}. Duration: {duration_hours:.1f} hours. Category: {duration_category}.\"\n",
    "    \n",
    "    # Get period info from finished date (for reporting)\n",
    "    period, period_week, period_year = get_period_info_for_date(finished_dt.date(), date_dim_df)\n",
    "    \n",
    "    task = {\n",
    "        'TaskId': generate_task_id(),\n",
    "        'RecordID': generate_record_id(),\n",
    "        'Instruction_Code': kpi_code,\n",
    "        'Building': station['Building'],\n",
    "        'BuildingName': station['BuildingName'],\n",
    "        'LocationName': station['LocationName'],\n",
    "        'ShortDescription': short_desc,\n",
    "        'LongDescription': long_desc,\n",
    "        'Reporter': reporter,\n",
    "        'ReporterEmail': email,\n",
    "        'Notes': f'Generated test data - {duration_category} duration',\n",
    "        'ReportedDate': reported_dt,\n",
    "        'DueBy': due_dt,\n",
    "        'ScheduledFor': scheduled_dt,\n",
    "        'Finished': finished_dt,\n",
    "        'Status': 'COMP',\n",
    "        'LoggedBy': random.choice(LOGGED_BY),\n",
    "        'LoggedOn': logged_dt,\n",
    "        'ModifiedOn': modified_dt,\n",
    "        'SLAStatus': sla_status,\n",
    "        'CreatedTimestamp': logged_dt,\n",
    "        'LastUploaded': datetime.now(),\n",
    "        'IsCurrent': 1,\n",
    "        'Period': period,\n",
    "        'PeriodWeek': period_week,\n",
    "        'PeriodYear': period_year,\n",
    "        'StationSection': station['StationSection'],\n",
    "        'KPIDescription': kpi_info['KPIDescription'],\n",
    "        'KPICategory': kpi_info['KPICategory'],\n",
    "    }\n",
    "    \n",
    "    return task\n",
    "\n",
    "print(\"✓ Core generation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Test Data with Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  MAIN DATA GENERATION\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"Generating test data...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_tasks = []\n",
    "\n",
    "# Calculate distribution\n",
    "kpi_codes_list = kpi_codes_df['KPICode'].tolist()\n",
    "num_kpis = len(kpi_codes_list)\n",
    "\n",
    "# Apply frequency weights if configured\n",
    "kpi_weights = []\n",
    "for kpi in kpi_codes_list:\n",
    "    weight = CONFIG['KPI_FREQUENCY_WEIGHTS'].get(kpi, 1.0)\n",
    "    kpi_weights.append(weight)\n",
    "\n",
    "# Normalize weights\n",
    "total_weight = sum(kpi_weights)\n",
    "kpi_weights = [w / total_weight for w in kpi_weights]\n",
    "\n",
    "# Calculate records per KPI\n",
    "base_records = CONFIG['TOTAL_RECORDS']\n",
    "\n",
    "# Reserve records for mandatory edge cases\n",
    "mandatory_year_spanning = num_kpis * CONFIG['YEAR_SPANNING_PER_KPI']\n",
    "mandatory_downtime = num_kpis * 3 if CONFIG['DOWNTIME_THRESHOLD_TESTS'] else 0\n",
    "mandatory_total = mandatory_year_spanning + mandatory_downtime\n",
    "\n",
    "remaining_records = base_records - mandatory_total\n",
    "\n",
    "print(f\"Total target records: {CONFIG['TOTAL_RECORDS']:,}\")\n",
    "print(f\"Mandatory edge cases: {mandatory_total:,}\")\n",
    "print(f\"  - Year-spanning: {mandatory_year_spanning}\")\n",
    "print(f\"  - Downtime tests: {mandatory_downtime}\")\n",
    "print(f\"Remaining for distribution: {remaining_records:,}\")\n",
    "print()\n",
    "\n",
    "# Date range\n",
    "start_date = pd.to_datetime(CONFIG['START_DATE'])\n",
    "end_date = start_date + timedelta(days=365 * CONFIG['PERIOD_YEARS'])\n",
    "\n",
    "# Financial year boundary (assuming April 1st)\n",
    "fy_boundary = pd.to_datetime(f\"{start_date.year + 1}-04-01\")\n",
    "\n",
    "print(f\"Date range: {start_date.date()} to {end_date.date()}\")\n",
    "print(f\"Financial year boundary: {fy_boundary.date()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  STEP 1: Generate Year-Spanning Tasks (Mandatory)\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"Step 1: Generating year-spanning tasks...\")\n",
    "\n",
    "for kpi_code in kpi_codes_list:\n",
    "    for _ in range(CONFIG['YEAR_SPANNING_PER_KPI']):\n",
    "        # Start before FY boundary, end after\n",
    "        start_before_fy = random_datetime(\n",
    "            fy_boundary - timedelta(days=90),\n",
    "            fy_boundary - timedelta(days=1)\n",
    "        )\n",
    "        \n",
    "        # Duration to ensure it crosses boundary\n",
    "        min_duration = ((fy_boundary - start_before_fy).total_seconds() / 3600) + 24\n",
    "        duration = random.uniform(min_duration, min_duration + 200)\n",
    "        \n",
    "        station = stations_df.sample(1).iloc[0]\n",
    "        task = create_base_task(\n",
    "            kpi_code, station, start_before_fy, duration,\n",
    "            duration_category='long', is_year_spanning=True\n",
    "        )\n",
    "        task['Notes'] = 'Year-spanning task - crosses FY boundary'\n",
    "        all_tasks.append(task)\n",
    "\n",
    "print(f\"  ✓ Generated {len(all_tasks)} year-spanning tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  STEP 2: Generate Downtime Threshold Tests (Optional)\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "if CONFIG['DOWNTIME_THRESHOLD_TESTS']:\n",
    "    print(\"\\nStep 2: Generating downtime threshold test tasks...\")\n",
    "    \n",
    "    threshold_hours = [24, 48, 100]\n",
    "    \n",
    "    for kpi_code in kpi_codes_list:\n",
    "        kpi_threshold = kpi_codes_df[kpi_codes_df['KPICode'] == kpi_code].iloc[0]['ThresholdHours']\n",
    "        \n",
    "        for threshold in threshold_hours:\n",
    "            # Create task that starts in year 1, uses threshold, closes in year 2\n",
    "            start_in_y1 = random_datetime(\n",
    "                fy_boundary - timedelta(days=120),\n",
    "                fy_boundary - timedelta(days=30)\n",
    "            )\n",
    "            \n",
    "            # Use some or all of year 2 threshold\n",
    "            y2_usage = random.uniform(threshold * 0.5, threshold)\n",
    "            total_duration = threshold + y2_usage\n",
    "            \n",
    "            station = stations_df.sample(1).iloc[0]\n",
    "            task = create_base_task(\n",
    "                kpi_code, station, start_in_y1, total_duration,\n",
    "                duration_category='long'\n",
    "            )\n",
    "            task['Notes'] = f'Downtime threshold test - {threshold}h threshold, Y1+Y2 rollover'\n",
    "            all_tasks.append(task)\n",
    "    \n",
    "    print(f\"  ✓ Generated {len(all_tasks) - mandatory_year_spanning} threshold test tasks\")\n",
    "else:\n",
    "    print(\"\\nStep 2: Skipped (downtime threshold tests disabled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  STEP 3: Generate Regular Tasks with Duration Mix\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\nStep 3: Generating regular tasks with mixed durations...\")\n",
    "\n",
    "tasks_before_regular = len(all_tasks)\n",
    "\n",
    "# Distribute remaining records across KPIs\n",
    "for i, kpi_code in enumerate(kpi_codes_list):\n",
    "    num_tasks = int(remaining_records * kpi_weights[i])\n",
    "    \n",
    "    # Ensure each duration category is represented\n",
    "    short_count = int(num_tasks * CONFIG['DURATION_CATEGORIES']['short']['weight'])\n",
    "    medium_count = int(num_tasks * CONFIG['DURATION_CATEGORIES']['medium']['weight'])\n",
    "    long_count = num_tasks - short_count - medium_count\n",
    "    \n",
    "    for category, count in [('short', short_count), ('medium', medium_count), ('long', long_count)]:\n",
    "        for _ in range(count):\n",
    "            reported_date = random_datetime(start_date, end_date - timedelta(days=30))\n",
    "            duration = generate_duration_hours(category)\n",
    "            station = stations_df.sample(1).iloc[0]\n",
    "            \n",
    "            task = create_base_task(\n",
    "                kpi_code, station, reported_date, duration,\n",
    "                duration_category=category\n",
    "            )\n",
    "            all_tasks.append(task)\n",
    "\n",
    "regular_tasks = len(all_tasks) - tasks_before_regular\n",
    "print(f\"  ✓ Generated {regular_tasks:,} regular tasks\")\n",
    "print(f\"  Total tasks so far: {len(all_tasks):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  STEP 4: Generate Period-Crossing Tasks\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\nStep 4: Ensuring period-crossing tasks...\")\n",
    "\n",
    "# Get unique periods from date dimension\n",
    "periods = date_dim_df.groupby(['Period', 'PeriodYear']).agg({\n",
    "    'Date': ['min', 'max']\n",
    "}).reset_index()\n",
    "periods.columns = ['Period', 'PeriodYear', 'PeriodStart', 'PeriodEnd']\n",
    "\n",
    "target_period_crossing = int(len(all_tasks) * CONFIG['PERIOD_BOUNDARY_CROSSING_RATIO'])\n",
    "period_crossing_created = 0\n",
    "\n",
    "# Create tasks that start in one period and end in another\n",
    "for _ in range(target_period_crossing):\n",
    "    # Pick a random period boundary\n",
    "    period_row = periods.sample(1).iloc[0]\n",
    "    period_end = pd.to_datetime(period_row['PeriodEnd'])\n",
    "    \n",
    "    # Start before period end, finish after\n",
    "    start_date_task = random_datetime(\n",
    "        period_end - timedelta(days=7),\n",
    "        period_end - timedelta(hours=1)\n",
    "    )\n",
    "    \n",
    "    # Duration to cross period\n",
    "    min_duration = ((period_end - start_date_task).total_seconds() / 3600) + 24\n",
    "    duration = random.uniform(min_duration, min_duration + 48)\n",
    "    \n",
    "    kpi_code = random.choice(kpi_codes_list)\n",
    "    station = stations_df.sample(1).iloc[0]\n",
    "    \n",
    "    task = create_base_task(\n",
    "        kpi_code, station, start_date_task, duration,\n",
    "        duration_category='medium'\n",
    "    )\n",
    "    task['Notes'] = 'Period-crossing task - crosses period boundary'\n",
    "    all_tasks.append(task)\n",
    "    period_crossing_created += 1\n",
    "\n",
    "print(f\"  ✓ Generated {period_crossing_created} period-crossing tasks\")\n",
    "print(f\"  Total tasks: {len(all_tasks):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  STEP 5: Generate Overlapping Groups (Duplicate Testing)\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "if CONFIG['CREATE_OVERLAPPING_GROUPS']:\n",
    "    print(\"\\nStep 5: Generating overlapping task groups for duplicate testing...\")\n",
    "    \n",
    "    overlap_created = 0\n",
    "    \n",
    "    for _ in range(CONFIG['OVERLAPPING_GROUPS_COUNT']):\n",
    "        # Pick a random station and KPI\n",
    "        station = stations_df.sample(1).iloc[0]\n",
    "        kpi_code = random.choice(kpi_codes_list)\n",
    "        \n",
    "        # Base time\n",
    "        base_time = random_datetime(start_date, end_date - timedelta(days=30))\n",
    "        \n",
    "        # Create 2-4 overlapping tasks\n",
    "        num_overlap = random.randint(2, 4)\n",
    "        \n",
    "        for i in range(num_overlap):\n",
    "            # Vary time within overlap window\n",
    "            task_time = base_time + timedelta(hours=random.uniform(0, CONFIG['OVERLAP_WINDOW_HOURS']))\n",
    "            duration = generate_duration_hours('short')\n",
    "            \n",
    "            task = create_base_task(\n",
    "                kpi_code, station, task_time, duration,\n",
    "                duration_category='short'\n",
    "            )\n",
    "            task['Notes'] = f'Overlapping group - duplicate test #{i+1}'\n",
    "            all_tasks.append(task)\n",
    "            overlap_created += 1\n",
    "    \n",
    "    print(f\"  ✓ Generated {overlap_created} tasks in overlapping groups\")\n",
    "    print(f\"  Total tasks: {len(all_tasks):,}\")\n",
    "else:\n",
    "    print(\"\\nStep 5: Skipped (overlapping groups disabled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  STEP 6: Generate Non-KPI Tasks (Optional)\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "if CONFIG['INCLUDE_NON_KPI_CODES']:\n",
    "    print(\"\\nStep 6: Generating non-KPI tasks...\")\n",
    "    \n",
    "    non_kpi_count = int(len(all_tasks) * CONFIG['NON_KPI_RATIO'])\n",
    "    \n",
    "    # Mock non-KPI codes\n",
    "    non_kpi_codes = ['GENERAL', 'ADMIN', 'INSPECTION', 'OTHER']\n",
    "    \n",
    "    for _ in range(non_kpi_count):\n",
    "        reported_date = random_datetime(start_date, end_date - timedelta(days=30))\n",
    "        duration = generate_duration_hours()\n",
    "        station = stations_df.sample(1).iloc[0]\n",
    "        kpi_code = random.choice(non_kpi_codes)\n",
    "        \n",
    "        # Create simplified task for non-KPI\n",
    "        task = create_base_task(\n",
    "            kpi_codes_list[0], station, reported_date, duration  # Use first KPI as template\n",
    "        )\n",
    "        task['Instruction_Code'] = kpi_code\n",
    "        task['KPIDescription'] = f'Non-KPI: {kpi_code}'\n",
    "        task['KPICategory'] = 'Non-KPI'\n",
    "        task['Notes'] = 'Non-KPI task - for testing'\n",
    "        all_tasks.append(task)\n",
    "    \n",
    "    print(f\"  ✓ Generated {non_kpi_count} non-KPI tasks\")\n",
    "    print(f\"  Total tasks: {len(all_tasks):,}\")\n",
    "else:\n",
    "    print(\"\\nStep 6: Skipped (non-KPI tasks disabled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  CREATE FINAL DATAFRAME\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Creating final dataset...\")\n",
    "\n",
    "df_test_data = pd.DataFrame(all_tasks)\n",
    "\n",
    "print(f\"\\n✓ Generated {len(df_test_data):,} total records\")\n",
    "print(f\"\\nData Summary:\")\n",
    "print(f\"  Date Range: {df_test_data['ReportedDate'].min()} to {df_test_data['Finished'].max()}\")\n",
    "print(f\"  Unique KPI Codes: {df_test_data['Instruction_Code'].nunique()}\")\n",
    "print(f\"  Unique Stations: {df_test_data['Building'].nunique()}\")\n",
    "print(f\"  Status: {df_test_data['Status'].value_counts().to_dict()}\")\n",
    "\n",
    "print(f\"\\nRecords per KPI Code:\")\n",
    "print(df_test_data['Instruction_Code'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nDuration Statistics (hours):\")\n",
    "df_test_data['DurationHours'] = (df_test_data['Finished'] - df_test_data['ScheduledFor']).dt.total_seconds() / 3600\n",
    "print(df_test_data['DurationHours'].describe())\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\nSample Records:\")\n",
    "display(df_test_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  DATA VALIDATION\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"Running validation checks...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "validation_issues = []\n",
    "\n",
    "# Check 1: All required columns present\n",
    "required_columns = [\n",
    "    'TaskId', 'RecordID', 'Instruction_Code', 'Building', 'BuildingName',\n",
    "    'LocationName', 'ShortDescription', 'LongDescription', 'Reporter',\n",
    "    'ReporterEmail', 'Notes', 'ReportedDate', 'DueBy', 'ScheduledFor',\n",
    "    'Finished', 'Status', 'LoggedBy', 'LoggedOn', 'ModifiedOn',\n",
    "    'SLAStatus', 'CreatedTimestamp', 'LastUploaded', 'IsCurrent',\n",
    "    'Period', 'PeriodWeek', 'PeriodYear', 'StationSection',\n",
    "    'KPIDescription', 'KPICategory'\n",
    "]\n",
    "\n",
    "missing_cols = set(required_columns) - set(df_test_data.columns)\n",
    "if missing_cols:\n",
    "    validation_issues.append(f\"Missing columns: {missing_cols}\")\n",
    "else:\n",
    "    print(\"✓ All required columns present\")\n",
    "\n",
    "# Check 2: No null values in critical columns\n",
    "critical_columns = ['TaskId', 'RecordID', 'Instruction_Code', 'Building', 'Status', 'Finished']\n",
    "for col in critical_columns:\n",
    "    null_count = df_test_data[col].isna().sum()\n",
    "    if null_count > 0:\n",
    "        validation_issues.append(f\"Null values in {col}: {null_count}\")\n",
    "\n",
    "if not validation_issues or len([i for i in validation_issues if 'Null values' in i]) == 0:\n",
    "    print(\"✓ No null values in critical columns\")\n",
    "\n",
    "# Check 3: Date logic\n",
    "date_issues = df_test_data[\n",
    "    (df_test_data['Finished'] < df_test_data['ReportedDate']) |\n",
    "    (df_test_data['ScheduledFor'] < df_test_data['ReportedDate'])\n",
    "]\n",
    "if len(date_issues) > 0:\n",
    "    validation_issues.append(f\"Invalid date sequences: {len(date_issues)} records\")\n",
    "else:\n",
    "    print(\"✓ Date logic is valid\")\n",
    "\n",
    "# Check 4: Year-spanning tasks\n",
    "fy_boundary = pd.to_datetime(f\"{start_date.year + 1}-04-01\")\n",
    "year_spanning = df_test_data[\n",
    "    (df_test_data['ReportedDate'] < fy_boundary) &\n",
    "    (df_test_data['Finished'] > fy_boundary)\n",
    "]\n",
    "print(f\"✓ Year-spanning tasks: {len(year_spanning)} (target: {mandatory_year_spanning})\")\n",
    "\n",
    "# Check 5: Status distribution\n",
    "if CONFIG['ALL_COMPLETED']:\n",
    "    non_comp = df_test_data[df_test_data['Status'] != 'COMP']\n",
    "    if len(non_comp) > 0:\n",
    "        validation_issues.append(f\"Non-COMP status found: {len(non_comp)} records\")\n",
    "    else:\n",
    "        print(\"✓ All tasks have COMP status\")\n",
    "\n",
    "# Check 6: Record count vs target\n",
    "variance = abs(len(df_test_data) - CONFIG['TOTAL_RECORDS']) / CONFIG['TOTAL_RECORDS']\n",
    "if variance > 0.1:  # More than 10% variance\n",
    "    validation_issues.append(f\"Record count variance: {variance*100:.1f}%\")\n",
    "else:\n",
    "    print(f\"✓ Record count within target (variance: {variance*100:.1f}%)\")\n",
    "\n",
    "# Check 7: Unique IDs\n",
    "dup_tasks = df_test_data['TaskId'].duplicated().sum()\n",
    "dup_records = df_test_data['RecordID'].duplicated().sum()\n",
    "if dup_tasks > 0 or dup_records > 0:\n",
    "    validation_issues.append(f\"Duplicate IDs - Tasks: {dup_tasks}, Records: {dup_records}\")\n",
    "else:\n",
    "    print(\"✓ All IDs are unique\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if validation_issues:\n",
    "    print(\"⚠ VALIDATION ISSUES FOUND:\")\n",
    "    for issue in validation_issues:\n",
    "        print(f\"  - {issue}\")\n",
    "else:\n",
    "    print(\"✅ ALL VALIDATION CHECKS PASSED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Output to Lakehouse / SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  OUTPUT TO LAKEHOUSE (FOR VALIDATION)\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "if CONFIG['OUTPUT_MODE'] == 'LAKEHOUSE':\n",
    "    print(\"Writing to Lakehouse for validation...\")\n",
    "    \n",
    "    try:\n",
    "        # Convert to Spark DataFrame\n",
    "        spark_df = spark.createDataFrame(df_test_data)\n",
    "        \n",
    "        # Write to Lakehouse\n",
    "        spark_df.write.mode(\"overwrite\").format(\"delta\").save(CONFIG['LAKEHOUSE_PATH'])\n",
    "        \n",
    "        print(f\"✓ Data written to {CONFIG['LAKEHOUSE_PATH']}\")\n",
    "        print(f\"  Records: {len(df_test_data):,}\")\n",
    "        print(\"\\n⚠ IMPORTANT: Review the data in Lakehouse before writing to SQL Server\")\n",
    "        print(\"  To write to SQL Server, change OUTPUT_MODE to 'SQL_SERVER' and re-run\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error writing to Lakehouse: {e}\")\n",
    "        print(\"Saving to CSV as backup...\")\n",
    "        csv_path = \"/lakehouse/default/Files/test_potential_failures.csv\"\n",
    "        df_test_data.to_csv(csv_path, index=False)\n",
    "        print(f\"✓ Data saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  OUTPUT TO SQL SERVER (AFTER VALIDATION)\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "if CONFIG['OUTPUT_MODE'] == 'SQL_SERVER':\n",
    "    print(\"Writing to SQL Server...\")\n",
    "    print(f\"Target table: {CONFIG['SQL_TABLE_NAME']}\")\n",
    "    \n",
    "    try:\n",
    "        # Convert to Spark DataFrame\n",
    "        spark_df = spark.createDataFrame(df_test_data)\n",
    "        \n",
    "        # Write to SQL Server\n",
    "        spark_df.write \\\n",
    "            .format(\"jdbc\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"url\", \"jdbc:sqlserver://<your_server>.database.windows.net:1433;database=<your_db>\") \\\n",
    "            .option(\"dbtable\", CONFIG['SQL_TABLE_NAME']) \\\n",
    "            .option(\"user\", \"<username>\") \\\n",
    "            .option(\"password\", \"<password>\") \\\n",
    "            .save()\n",
    "        \n",
    "        print(f\"✓ Data written to SQL Server\")\n",
    "        print(f\"  Table: {CONFIG['SQL_TABLE_NAME']}\")\n",
    "        print(f\"  Records: {len(df_test_data):,}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error writing to SQL Server: {e}\")\n",
    "        print(\"Please update JDBC connection details in the code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optional: Generate Status History Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  GENERATE STATUS HISTORY (WAPPR → APPR → COMP)\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "if CONFIG['GENERATE_STATUS_HISTORY']:\n",
    "    print(\"Generating status history files...\")\n",
    "    \n",
    "    # Take a sample of records to create history for\n",
    "    sample_size = min(1000, len(df_test_data))\n",
    "    history_tasks = df_test_data.sample(sample_size).copy()\n",
    "    \n",
    "    all_history = []\n",
    "    \n",
    "    for idx, row in history_tasks.iterrows():\n",
    "        # WAPPR (Waiting Approval)\n",
    "        wappr_record = row.copy()\n",
    "        wappr_record['Status'] = 'WAPPR'\n",
    "        wappr_record['Finished'] = pd.NaT\n",
    "        wappr_record['ModifiedOn'] = row['LoggedOn'] + timedelta(hours=1)\n",
    "        wappr_record['LastUploaded'] = wappr_record['ModifiedOn']\n",
    "        all_history.append(wappr_record)\n",
    "        \n",
    "        # APPR (Approved)\n",
    "        appr_record = row.copy()\n",
    "        appr_record['Status'] = 'APPR'\n",
    "        appr_record['Finished'] = pd.NaT\n",
    "        appr_record['ModifiedOn'] = row['ScheduledFor'] - timedelta(hours=1)\n",
    "        appr_record['LastUploaded'] = appr_record['ModifiedOn']\n",
    "        all_history.append(appr_record)\n",
    "        \n",
    "        # COMP (Completed) - original record\n",
    "        comp_record = row.copy()\n",
    "        all_history.append(comp_record)\n",
    "    \n",
    "    df_history = pd.DataFrame(all_history)\n",
    "    \n",
    "    # Sort by TaskId and ModifiedOn\n",
    "    df_history = df_history.sort_values(['TaskId', 'ModifiedOn'])\n",
    "    \n",
    "    # Save history files\n",
    "    history_path = \"/lakehouse/default/Files/test_potential_failures_history.csv\"\n",
    "    df_history.to_csv(history_path, index=False)\n",
    "    \n",
    "    print(f\"✓ Generated {len(df_history):,} history records for {sample_size} tasks\")\n",
    "    print(f\"  Saved to: {history_path}\")\n",
    "    print(f\"  Status breakdown: {df_history['Status'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"Status history generation skipped (disabled in config)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  FINAL SUMMARY\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n📊 DATA SUMMARY\")\n",
    "print(f\"  Total Records: {len(df_test_data):,}\")\n",
    "print(f\"  Date Range: {df_test_data['ReportedDate'].min().date()} to {df_test_data['Finished'].max().date()}\")\n",
    "print(f\"  KPI Codes: {df_test_data['Instruction_Code'].nunique()}\")\n",
    "print(f\"  Stations: {df_test_data['Building'].nunique()}\")\n",
    "\n",
    "print(f\"\\n✅ EDGE CASES COVERED\")\n",
    "print(f\"  Year-spanning tasks: {len(year_spanning)}\")\n",
    "print(f\"  Period-crossing tasks: {period_crossing_created}\")\n",
    "if CONFIG['CREATE_OVERLAPPING_GROUPS']:\n",
    "    print(f\"  Overlapping task groups: {CONFIG['OVERLAPPING_GROUPS_COUNT']}\")\n",
    "if CONFIG['DOWNTIME_THRESHOLD_TESTS']:\n",
    "    print(f\"  Downtime threshold tests: {mandatory_downtime}\")\n",
    "\n",
    "print(f\"\\n📁 OUTPUT\")\n",
    "if CONFIG['OUTPUT_MODE'] == 'LAKEHOUSE':\n",
    "    print(f\"  Location: {CONFIG['LAKEHOUSE_PATH']}\")\n",
    "    print(f\"  ⚠ Review data before writing to SQL Server\")\n",
    "else:\n",
    "    print(f\"  Table: {CONFIG['SQL_TABLE_NAME']}\")\n",
    "\n",
    "print(f\"\\n🔧 NEXT STEPS\")\n",
    "print(\"  1. Review the generated data in Lakehouse\")\n",
    "print(\"  2. Verify edge cases and date distributions\")\n",
    "print(\"  3. Run additional validation queries if needed\")\n",
    "print(\"  4. Change OUTPUT_MODE to 'SQL_SERVER' when ready\")\n",
    "print(\"  5. Update JDBC connection details in cell above\")\n",
    "print(\"  6. Re-run to write to SQL Server\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
